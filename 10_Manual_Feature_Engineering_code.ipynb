{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "from mlwpy import *\n",
    "%matplotlib inline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "(iris_train,     iris_test, \n",
    " iris_train_tgt, iris_test_tgt) = skms.train_test_split(iris.data,\n",
    "                                                        iris.target, \n",
    "                                                        test_size=.25)\n",
    "# remove units ' (cm)' from names\n",
    "iris.feature_names = [fn[:-5] for fn in iris.feature_names]\n",
    "\n",
    "# dataframe for convenience\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target_names[iris.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "f_temps = np.linspace(0, 212, 100)\n",
    "c_temps = (5/9) * (f_temps - 32)\n",
    "plt.plot(f_temps, f_temps, 'r',  # F -> F\n",
    "         f_temps, c_temps, 'b');  # F -> C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "original = np.random.uniform(-5, 5, 100)\n",
    "scaled = skpre.StandardScaler().fit_transform(original.reshape(-1,1))[:,0]\n",
    "bins = np.floor(original).astype(np.uint8) + 5\n",
    "\n",
    "df = pd.DataFrame({'original':original,\n",
    "                   'scaled':scaled,\n",
    "                   'hue':bins})\n",
    "df = pd.melt(df, id_vars='hue', var_name='scale')\n",
    "\n",
    "sns.swarmplot(x='scale', y='value', hue='hue', data=df).legend_.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "bins = pd.cut(iris_df['sepal width'], \n",
    "              np.percentile(iris_df['sepal width'], \n",
    "                            [25, 50, 75, 100])).cat.codes\n",
    "\n",
    "df = pd.DataFrame({'orig':iris_df['sepal width'],\n",
    "                   'hue':bins})\n",
    "\n",
    "scalers = [('std', skpre.StandardScaler()),\n",
    "           ('01' , skpre.MinMaxScaler()),\n",
    "           ('-1,1', skpre.MinMaxScaler((-1,1)))]\n",
    "\n",
    "for name, scaler in scalers:\n",
    "     # ugly:  [[]] to keep 2D for sklearn\n",
    "     #        reshape(-1) to go back to 1-D for seaborn  :(\n",
    "    df[name] = scaler.fit_transform(df[['orig']]).reshape(-1)\n",
    "\n",
    "df = pd.melt(df, id_vars='hue', var_name='scale')\n",
    "sns.swarmplot(x='scale', y='value', hue='hue', data=df).legend_.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target_names[iris.target]\n",
    "display(iris_df.iloc[[0,50,100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(4,3))\n",
    "ax = sns.distplot(iris_df['sepal length'], hist=False, rug=True)\n",
    "ax.set_ylabel(\"Approximate %\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply binary threshold to numeric with sklearn is tricky\n",
    "column = iris_df[['sepal length']] # keep 2Dness b/c sk complains\n",
    "col_mean = column.mean().values    # and sk fails with Series/DF\n",
    "\n",
    "both = column.copy()\n",
    "both['> Mean'] = skpre.binarize(column, col_mean).astype(np.bool)\n",
    "\n",
    "print('Column Mean:', col_mean)\n",
    "display(both.iloc[[0,50,100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_len_series = iris_df['sepal length']\n",
    "breaks = [sep_len_series.mean(), \n",
    "          sep_len_series.max()]\n",
    "\n",
    "# ugly to extract\n",
    "print(pd.cut(sep_len_series, breaks).cat.codes[[0, 50, 100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an easy button:\n",
    "np.where(column > column.mean(), True, False)[[0,50,100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close your eyes Francis, this is about to get ugly\n",
    "# this pandas voodoo is simply to produce a labelled dataframe\n",
    "# so you can *see* the learning problem I am describing in the text\n",
    "\n",
    "new_iris_df = pd.DataFrame(iris_df, columns=['petal length', \n",
    "                                             'petal width', \n",
    "                                             'species'])\n",
    "\n",
    "new_iris_df.columns = pd.MultiIndex([['input ftrs', 'target ftr'],\n",
    "                                      new_iris_df.columns], \n",
    "                                     [[1, 0, 0], [0,1,2]])\n",
    "\n",
    "new_iris_df.sort_index(axis='columns', inplace=True)\n",
    "display(new_iris_df.iloc[[0,50,100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with category numbers\n",
    "print(\"Numerical categories:\",\n",
    "      iris.target[[0, 50, 100]], sep='\\n')\n",
    "\n",
    "# produces sparse representation\n",
    "sparse = (skpre.OneHotEncoder(categories='auto')\n",
    "               .fit_transform(iris.target.reshape(-1,1)))\n",
    "\n",
    "# densify it\n",
    "print(\"One-hot coding:\", \n",
    "      sparse[[0,50,100]].todense(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use drop_first to get treatment coding\n",
    "# can request sparse storage\n",
    "encoded = pd.get_dummies(iris_df, prefix=\"is\") \n",
    "encoded.iloc[[0,50,100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splicing dataframes together by merging\n",
    "# recall `iris.target` is in terms of 0,1,2 not symbolic setosa, etc.\n",
    "encoded_species = pd.get_dummies(iris.target)\n",
    "encoded_df = pd.merge(iris_df, encoded_species, \n",
    "                      right_index=True, left_index=True)\n",
    "encoded_df.iloc[[0,50,100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy.contrasts as pc\n",
    "\n",
    "levels = iris.target_names\n",
    "coding = (pc.Treatment(reference=0)\n",
    "            .code_with_intercept(list(levels)))\n",
    "print(coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = patsy.dmatrix('species-1', \n",
    "                        iris_df, \n",
    "                        return_type='dataframe')\n",
    "display(encoded.iloc[[0,50,100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = patsy.dmatrix('species', \n",
    "                        iris_df, \n",
    "                        return_type='dataframe')\n",
    "display(encoded.iloc[[0,50,100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_data = pd.DataFrame({'pet' :['cat', 'cat', 'dog'],\n",
    "                         'cost':[20.0,   25.0,  40.0]})\n",
    "\n",
    "pet_df = pd.get_dummies(pet_data)\n",
    "display(pet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_coeffs(sk_lr_model, ftr_names):\n",
    "    ' helper to display sklearn results in a nice dataframe '\n",
    "    lr_coeffs = pd.DataFrame(sk_lr_model.coef_, \n",
    "                             columns=ftr_names, \n",
    "                             index=['Coeff'])\n",
    "    lr_coeffs['intercept'] = sk_lr_model.intercept_\n",
    "    return lr_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# massage\n",
    "sk_tgt  = pet_df['cost'].values.reshape(-1,1)\n",
    "sk_ftrs = pet_df.drop('cost', axis='columns')\n",
    "\n",
    "# build-model\n",
    "sk_model = (linear_model.LinearRegression(fit_intercept=False)\n",
    "                       .fit(sk_ftrs, sk_tgt))\n",
    "display(pretty_coeffs(sk_model, sk_ftrs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patsy formula that explicitly removes an intercept\n",
    "formula = 'cost ~ pet - 1'\n",
    "sm_model = smf.ols(formula, data=pet_data).fit()\n",
    "display(pd.DataFrame(sm_model.params).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_tgt  = pet_df['cost'].values.reshape(-1,1)\n",
    "sk_ftrs = pet_df.drop('cost', axis='columns')\n",
    "sk_model = (linear_model.LinearRegression()   #  fit_intercept=True by default!\n",
    "                       .fit(sk_ftrs, sk_tgt))\n",
    "display(pretty_coeffs(sk_model, sk_ftrs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_data_p1 = pet_data.copy()  # don't muck the original data\n",
    "pet_data_p1['ones'] = 1.0      # manual +1 trick\n",
    "\n",
    "#   remove coding intercept ..... add manual ones == add manual intercept\n",
    "formula = 'cost ~ (pet - 1)  + ones'\n",
    "sm_model = smf.ols(formula, data=pet_data_p1).fit()\n",
    "display(pd.DataFrame(sm_model.params).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row-slicing is annoying, but have to get to single-D things and \n",
    "# .flat gives a warning in the DF constructor\n",
    "df = pd.DataFrame({'predicted_sk' : sk_model.predict(sk_ftrs)[:,0],\n",
    "                  'predicted_sm' : sm_model.predict(pet_data_p1),\n",
    "                  'actual'       : sk_tgt[:,0]})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pet_data_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pet - 1 coding')\n",
    "print(patsy.dmatrix('pet - 1', data=pet_data_p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens when we add up the coding columns\n",
    "print(\"column sum:\")\n",
    "full_coding = patsy.dmatrix('pet - 1', \n",
    "                            data=pet_data_p1, \n",
    "                            return_type='dataframe')\n",
    "display(pd.DataFrame(full_coding.sum(axis='columns')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_data = [[0,0,0],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,0]]\n",
    "xor_df = pd.DataFrame(xor_data, \n",
    "                      columns=['x1','x2','tgt'])\n",
    "display(xor_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (linear_model.LogisticRegression()\n",
    "                     .fit(xor_df[['x1', 'x2']], \n",
    "                          xor_df['tgt']))\n",
    "model.predict(xor_df[['x1', 'x2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(2,2))\n",
    "ax.scatter('x1', 'x2', data=xor_df, c='tgt')\n",
    "ax.set_xlim(-1, 2)\n",
    "ax.set_ylim(-1, 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_df['new'] = (-1)**xor_df['x1'] * (-1)**xor_df['x2']\n",
    "xor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression().fit(xor_df[['new']], \n",
    "                                              xor_df['tgt'])\n",
    "model.predict(xor_df[['new']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "# degree            degree of terms\n",
    "# interaction_only  no x**2, only x*y (and x,y)\n",
    "# include_bias      constant term\n",
    "quad_inters = skpre.PolynomialFeatures(degree=2,              # degree of terms\n",
    "                                       interaction_only=True, # no x**2, only x*y\n",
    "                                       include_bias=False)    # constant term\n",
    "subset = iris_df.loc[[0, 50, 100], ['sepal length', 'sepal width']]\n",
    "new_terms = pd.DataFrame(quad_inters.fit_transform(subset), \n",
    "                         index=[0, 50, 100])\n",
    "new_terms.set_axis(['sep length', 'sep width', 'sep area'], \n",
    "                   axis=1, inplace=True)\n",
    "\n",
    "# note:  creating the interaction *also* \n",
    "# includes the base terms in the interaction\n",
    "display(new_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_df = patsy.dmatrix(\"Q('sepal length'):Q('sepal width') - 1\", \n",
    "                          data=iris_df.iloc[[0, 50, 100]],\n",
    "                          return_type='dataframe')\n",
    "design_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some areas\n",
    "sepal_area = iris_df['sepal length'] * iris_df['sepal width']\n",
    "petal_area = iris_df['petal length'] * iris_df['petal width']\n",
    "\n",
    "# discretize \n",
    "iris_df['big_sepal'] = sepal_area > sepal_area.median()\n",
    "iris_df['big_petal'] = petal_area > petal_area.median()\n",
    "display(iris_df.iloc[[0,50,100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_df = patsy.dmatrix(\"big_sepal:big_petal - 1\", \n",
    "                          data=iris_df.iloc[[0, 50, 100]],\n",
    "                          return_type='dataframe')\n",
    "\n",
    "# breaking up the long column names\n",
    "display(design_df.iloc[:, :2])\n",
    "display(design_df.iloc[:,2: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we (Q)uote sepal length b/c it has a space in the name\n",
    "design_df = patsy.dmatrix(\"C(species,Treatment):Q('sepal length') - 1\", \n",
    "                        data=iris_df.iloc[[0, 50, 100]],\n",
    "                        return_type='dataframe')\n",
    "\n",
    "# breaking up the long column names\n",
    "display(design_df.iloc[:,[0]])\n",
    "display(design_df.iloc[:,[1]])\n",
    "display(design_df.iloc[:,[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_df.iloc[[0, 50, 100]]['sepal length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can build a design matrix and send it to sklearn\n",
    "design = \"C(species,Treatment):petal_area\"\n",
    "design_matrix = patsy.dmatrix(design, data=iris_df)\n",
    "\n",
    "# intercept is already in design matrix\n",
    "lr = linear_model.LinearRegression(fit_intercept=False) \n",
    "mod = lr.fit(design_matrix, iris_df['sepal width'])\n",
    "print(mod.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hey, we get the same results!\n",
    "formula = \"Q('sepal width') ~ C(species,Treatment):petal_area\"\n",
    "res1 = smf.ols(formula=formula, data=iris_df).fit()\n",
    "print(res1.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target_names[iris.target]\n",
    "\n",
    "area_df = pd.DataFrame({\"sepal_area\" : iris_df['sepal length'] * \n",
    "                                       iris_df['sepal width'],\n",
    "                        \"petal_area\" : iris_df['petal length'] * \n",
    "                                       iris_df['petal width']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_big_small(d):\n",
    "    return d > np.median(d)\n",
    "\n",
    "transformer = skpre.FunctionTransformer(median_big_small)\n",
    "res = transformer.fit_transform(area_df)\n",
    "\n",
    "print(\"Large areas as compared to median?\")\n",
    "# updated Fall 2020.  used to work (possibly b/c dataframe\n",
    "# -> array in fit_transform?)  regardless, results is\n",
    "# a dataframe so we have to access rows\n",
    "print(res.iloc[[0, 50, 100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "class Median_Big_Small(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, ftrs, tgt=None):\n",
    "        self.medians = np.median(ftrs)\n",
    "        return self\n",
    "    def transform(self, ftrs, tgt=None):\n",
    "        return ftrs > self.medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training-testing split\n",
    "training, testing = skms.train_test_split(area_df)\n",
    "    \n",
    "# create and run the transformer\n",
    "transformer = Median_Big_Small()\n",
    "train_xform = transformer.fit_transform(training)\n",
    "test_xform  = transformer.transform(testing)\n",
    "\n",
    "# the dataframes survived!\n",
    "print('train:')\n",
    "display(train_xform[:3])\n",
    "print('test:')\n",
    "display(test_xform[ :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,10,50)\n",
    "n1 = np.random.normal(size=x.shape)\n",
    "\n",
    "comparison = pd.DataFrame({\"x\"  : x,\n",
    "                           \"d1\" : 2*x+5    + n1,\n",
    "                           \"d2\" : 2*x**2+5 + n1})\n",
    "\n",
    "comparison['x'] = x\n",
    "melted = pd.melt(comparison, id_vars=['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='x', y='value',\n",
    "           data=melted, col='variable', ci=None,\n",
    "           height=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(8,3))\n",
    "for ax, variable in zip(axes, ['d1', 'd2']):\n",
    "    predicted = (smf.ols(\"{} ~ x\".format(variable), data=comparison)\n",
    "                    .fit()\n",
    "                    .predict())\n",
    "    actual = comparison[variable]\n",
    "    sns.distplot(predicted - actual, norm_hist=True, rug=True, ax=ax)\n",
    "    ax.set_xlabel(variable)\n",
    "    ax.set_ylabel('residual')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic = pd.DataFrame({\"d2\"   : 2*x**2+5+n1,\n",
    "                      \"x_sq\" : x**2})\n",
    "melted = pd.melt(magic, id_vars=['x_sq'])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "sns.regplot(x='x_sq', y='value', \n",
    "            data=melted, ci=None, ax=ax1)\n",
    "\n",
    "predicted = (smf.ols(\"d2 ~ x_sq\", data=magic)\n",
    "                .fit()\n",
    "                .predict())\n",
    "actual = comparison['d2']\n",
    "sns.distplot(predicted - actual, rug=True, \n",
    "             norm_hist = True, ax=ax2)\n",
    "\n",
    "ax2.set_title('histogram')\n",
    "ax2.set_xlim(-3,3)\n",
    "ax2.set_ylim(0,.45)\n",
    "ax2.set_ylabel('residual');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,10,50)\n",
    "\n",
    "n1 = np.random.normal(size=x.shape)\n",
    "n2 = .5*x*np.random.normal(size=x.shape)\n",
    "\n",
    "comparison = pd.DataFrame({\"x\"  : x,\n",
    "                           \"d1\" : 2*x+5+n1,\n",
    "                           \"d2\" : 2*x+5+n2})\n",
    "\n",
    "comparison['x'] = x\n",
    "melted = pd.melt(comparison, id_vars=['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='x', y='value', \n",
    "           data=melted, col='variable', ci=None,\n",
    "           height=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(8,3))\n",
    "for ax, variable in zip(axes, ['d1', 'd2']):\n",
    "    predicted = (smf.ols(\"{} ~ x\".format(variable), data=comparison)\n",
    "                    .fit()\n",
    "                    .predict())\n",
    "    actual = comparison[variable]\n",
    "    sns.distplot(predicted - actual, norm_hist=True, rug=True, ax=ax)\n",
    "    ax.set_xlabel(variable)\n",
    "    ax.set_ylabel('residual')\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic = pd.DataFrame({\"log_d2\" : np.log(comparison['d2']),\n",
    "                      \"x\"      : x})\n",
    "melted = pd.melt(magic, id_vars=['x'])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "sns.regplot(x='x', y='value', data=melted, \n",
    "            ci=None, ax=ax1)\n",
    "\n",
    "predicted = (smf.ols(\"log_d2 ~ x\", data=magic)\n",
    "                .fit()\n",
    "                .predict())\n",
    "actual = magic['log_d2']\n",
    "sns.distplot(predicted - actual, rug=True, ax=ax2)\n",
    "\n",
    "ax2.set_title('histogram')\n",
    "ax2.set_xlim(-.7, .7)\n",
    "ax2.set_ylim(0,3)\n",
    "ax2.set_ylabel('residual');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,8,100)\n",
    "n1 = np.random.normal(size=x.shape)\n",
    "n2 = x * np.random.normal(size=x.shape)\n",
    "\n",
    "mystery = {'m1':5 + n1,\n",
    "           'm2':5 + n2,\n",
    "           'm3':x + n1,\n",
    "           'm4':x + n2,\n",
    "           'm5':np.log2(x) + n1,\n",
    "           'm6':np.log2(x) + n2,\n",
    "           'm7':np.exp2(x + n1),\n",
    "           'm8':np.exp2(x + n2)}\n",
    "\n",
    "mystery_df = pd.DataFrame(mystery)\n",
    "mystery_df['x'] = x"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
